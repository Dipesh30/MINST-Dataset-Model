{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lkd4boJK-vDj",
        "outputId": "9842d5de-97e9-466f-ef06-f3801760405b"
      },
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "import numpy\n",
        "import cv2\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv3D, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "K.image_data_format()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'channels_last'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUVdRQ6bB93O",
        "outputId": "596fc704-c4a3-468b-8400-72f7d47b5fda"
      },
      "source": [
        "# Fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape to be samples*pixels*width*height\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "\n",
        "# Normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# One Hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee5-G6GiCCGN",
        "outputId": "2f6cc494-c65b-4ef7-ce31-6c1f563b35c5"
      },
      "source": [
        "# Create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape=(1, 28, 28), activation='relu', strides = 1, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same', data_format='channels_last'))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', strides = 1, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same', data_format='channels_last'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 13s 3ms/step - loss: 0.6236 - accuracy: 0.7979 - val_loss: 0.0980 - val_accuracy: 0.9685\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1522 - accuracy: 0.9526 - val_loss: 0.0738 - val_accuracy: 0.9752\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1069 - accuracy: 0.9664 - val_loss: 0.0563 - val_accuracy: 0.9812\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9717 - val_loss: 0.0524 - val_accuracy: 0.9823\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9746 - val_loss: 0.0437 - val_accuracy: 0.9838\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0704 - accuracy: 0.9769 - val_loss: 0.0540 - val_accuracy: 0.9832\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0636 - accuracy: 0.9803 - val_loss: 0.0461 - val_accuracy: 0.9853\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0389 - val_accuracy: 0.9881\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.0414 - val_accuracy: 0.9867\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 0.0415 - val_accuracy: 0.9870\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0521 - accuracy: 0.9829 - val_loss: 0.0379 - val_accuracy: 0.9882\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0479 - accuracy: 0.9839 - val_loss: 0.0346 - val_accuracy: 0.9880\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.0355 - val_accuracy: 0.9894\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.0416 - val_accuracy: 0.9865\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.0375 - val_accuracy: 0.9873\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0393 - accuracy: 0.9867 - val_loss: 0.0343 - val_accuracy: 0.9886\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 0.0326 - val_accuracy: 0.9895\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0412 - accuracy: 0.9862 - val_loss: 0.0380 - val_accuracy: 0.9876\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 0.0341 - val_accuracy: 0.9895\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.0368 - val_accuracy: 0.9879\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.0377 - val_accuracy: 0.9878\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0309 - val_accuracy: 0.9901\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0326 - val_accuracy: 0.9898\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 0.0362 - val_accuracy: 0.9899\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.0396 - val_accuracy: 0.9884\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0353 - val_accuracy: 0.9892\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.0395 - val_accuracy: 0.9882\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.0345 - val_accuracy: 0.9903\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0453 - val_accuracy: 0.9879\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.0343 - val_accuracy: 0.9901\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.0392 - val_accuracy: 0.9888\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.0352 - val_accuracy: 0.9898\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.0336 - val_accuracy: 0.9903\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.0328 - val_accuracy: 0.9912\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0370 - val_accuracy: 0.9895\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0417 - val_accuracy: 0.9884\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.0340 - val_accuracy: 0.9907\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.0359 - val_accuracy: 0.9900\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0382 - val_accuracy: 0.9892\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0367 - val_accuracy: 0.9899\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0358 - val_accuracy: 0.9901\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0442 - val_accuracy: 0.9884\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0362 - val_accuracy: 0.9910\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0398 - val_accuracy: 0.9886\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0399 - val_accuracy: 0.9894\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.0352 - val_accuracy: 0.9905\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0393 - val_accuracy: 0.9904\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0479 - val_accuracy: 0.9899\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0440 - val_accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0373 - val_accuracy: 0.9887\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0402 - val_accuracy: 0.9898\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0369 - val_accuracy: 0.9904\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0371 - val_accuracy: 0.9900\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0378 - val_accuracy: 0.9903\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0429 - val_accuracy: 0.9895\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0388 - val_accuracy: 0.9892\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0447 - val_accuracy: 0.9885\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0420 - val_accuracy: 0.9896\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0481 - val_accuracy: 0.9886\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0455 - val_accuracy: 0.9885\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0461 - val_accuracy: 0.9878\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0411 - val_accuracy: 0.9894\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0416 - val_accuracy: 0.9899\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0414 - val_accuracy: 0.9900\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0425 - val_accuracy: 0.9897\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.0434 - val_accuracy: 0.9900\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0448 - val_accuracy: 0.9897\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0445 - val_accuracy: 0.9895\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0462 - val_accuracy: 0.9888\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.0461 - val_accuracy: 0.9889\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0478 - val_accuracy: 0.9882\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9892\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0497 - val_accuracy: 0.9873\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0400 - val_accuracy: 0.9893\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0435 - val_accuracy: 0.9890\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0399 - val_accuracy: 0.9893\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0467 - val_accuracy: 0.9890\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0439 - val_accuracy: 0.9891\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0429 - val_accuracy: 0.9896\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0531 - val_accuracy: 0.9882\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0458 - val_accuracy: 0.9893\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0469 - val_accuracy: 0.9890\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0466 - val_accuracy: 0.9888\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.0467 - val_accuracy: 0.9906\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0447 - val_accuracy: 0.9899\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0493 - val_accuracy: 0.9903\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0511 - val_accuracy: 0.9882\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0497 - val_accuracy: 0.9891\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0447 - val_accuracy: 0.9890\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0429 - val_accuracy: 0.9883\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0459 - val_accuracy: 0.9901\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0485 - val_accuracy: 0.9888\n",
            "Large CNN Error: 1.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aurZsotICmiq",
        "outputId": "b351bce9-4d1a-4917-eeb4-e9b46a6cf5a9"
      },
      "source": [
        "#  - - - - - - - TEST single image - - - - - - - -\n",
        "\n",
        "image = (X_test[1]).reshape(1,1,28,28) # 1->'2';\n",
        "model_pred = model.predict_classes(image, verbose = 0)\n",
        "print('Prediction of model: {}'.format(model_pred[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of model: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "7c9CFxFgE0dD",
        "outputId": "de6091d1-a63f-45d1-f636-06a6dd3890dc"
      },
      "source": [
        "# - - - - - - TESTING multiple image - - - - - - - - - -\n",
        "\n",
        "test_images = X_test[1:5]\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28)\n",
        "print (\"Test images shape: {}\".format(test_images.shape))\n",
        "\n",
        "for i, test_image in enumerate(test_images, start=1):\n",
        "    org_image = test_image\n",
        "    test_image = test_image.reshape(1,1,28,28)\n",
        "    prediction = model.predict_classes(test_image, verbose=0)\n",
        "\n",
        "    print (\"Predicted digit: {}\".format(prediction[0]))\n",
        "    plt.subplot(220+i)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Predicted digit: {}\".format(prediction[0]))\n",
        "    plt.imshow(org_image, cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test images shape: (4, 28, 28)\n",
            "Predicted digit: 2\n",
            "Predicted digit: 1\n",
            "Predicted digit: 0\n",
            "Predicted digit: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAD3CAYAAABFL3JUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYD0lEQVR4nO3de5AV1Z0H8O/XYXjMSBBUfBCEwJQoEgQiAgpiXEpQQYGAsFIJrGWMRqIVCZpCtsQIhYUuqAGhTK0VDKsSBRUU4mMjIKvGGiJYIUAEwwA6yGMAGcDI4+wf90zT3U7f6TvcR5/x+6m6xe/cc7r7zO0zvznd9O2mMQYiIkl3WqE7ICISh5KViDhByUpEnKBkJSJOULISEScoWYmIEwqarEj+nuRUG/cjuSlP2zUky2K2nUJygY0vIFlNsijGcrHbSsOjsZ19dSYrkltJHrGd+8LuhNOz3RFjzLvGmE4x+jOO5Opsbz8OY8w2Y8zpxpjjmbYluYLkbXG3RfJCkq+S3E2yiuQbJOv8fCQ+je2T8jm27TJPk9xE8gTJcXGWiTuzGmKMOR1ADwCXAZhcy8Ybxe6pxHEGgCUAOgE4B8CHAF4taI8aJo3twlgH4OcA/hp3gYwOA40xnwFYDqAL4E057yL5CYBP7HuDSa4luZ/keyS71ixPsjvJv5I8SHIhgKa+uqtJ7vCV25JcbGcWe0nOJnkxgHkA+ti/hvtt2yYkHyO5zf6FnEeymW9dE0lWkvyc5K3pfkaS3yO50vbxLQBn+era25+5ka/tKtv2bZJzfNNqry3JaQD6AZht+z07xmf9oTHmv40xVcaYowBmAehE8sy6lpXMaWznb2zbz3uOMeZ/AXwVp33NQmlfALYCGGDjtgDWA3jYlg2AtwC0AtAMQHcAuwD0AlAEYKxdvgmAxgAqAPwSQDGAEQCOAphq13U1gB02LkIq884CUIrUju9r68YBWB3q4yykZiGtADQHsBTAdFs3CMAXSA3CUgDP2X6XRfy87wOYaft8FYCDABbYuvZ22Ua+to/Zn60vgC/TtF0B4LbQtl4D8Ou69oFtOxRAZZy2esV7aWwXfmwDWA1gXKz9FXOHVgPYb3fIUwCa+XboNb62c2t2tu+9TQD62w/ncwD01b0XsUP7ANhd82GE1hfYoQAI4BCAjr73+gD4p42fAfCIr+7CqB0K4AIAxwCU+t57rrad5Gtb4mu7IJMdmsEv1XcBfAbg3wv9C96QXhrbiRjbsZNV3GPxocaYtyPqtvvidgDGkvyF773GAM63P9xnxvbQqohYZ1sAFcaYYzH6djaAEgBrSNa8R6T+gsFue02Mbda03WeMORRq3zaibZUx5rDvve0RbeuN5NkA3gTwlDHm+WyuWwBobBdsbGcqG5cu+HfQdgDTjDFn+F4l9pesEkAb+j51pDJ4bbYDuCDixGb4NhF7ABwBcIlvmy1M6qQp7Hb9H3LUNmvatiRZGqN9JYBWJEt876XbmRnf3oJkS6QS1RJjzLRMl5dTprF9UlbHdn1k+zqr3wG4g2QvppSSvIFkc6SOgY8BuJtkMcnhAC6PWM+HSH1gj9h1NCV5pa37AsB3STYGAGPMCbvdWSRbAwDJNiQH2vZ/BDCOZGf74T8Y1XljTAWAcgAPkWxMsi+AIXW0nWLb9olq6+t3hzT1ASS/A+ANAP9njPl13OUkZzS2o2U0tu3P0ZhkU6RmisX2c0ibj7KarIwx5QB+CmA2gH0ANiN1HA5jzNcAhttyFYBRABZHrOc4Uh9OGYBtAHbY9gDwZ6ROhO4kuce+d7/d1gckvwTwNlL/5Q9jzHIAj9vlNtt/07kFqZOoVUjt/GfTtB2D1DmEvQCmAlgI4F8RbZ8AMILkPpJPAgDJ5SQnRbQfBqAngP+w/8tS80r311NyRGM7q2MbSB0xHAFwBYCnbXxVus4zeJgtp4Kp/7LeaIyJ/Asn4qIkjG19N/AUkOxJsiPJ00gOAnATgFcK3S+RU5XEsa0rc0/NuUhN989Eajp/pzHmo8J2SSQrEje2dRgoIk7QYaCIOCHWYSBJTb8SwhjDultJXBrbyVHX2NbMSkScoGQlIk5QshIRJyhZiYgTlKxExAlKViLiBCUrEXGCkpWIOEHJSkScoGQlIk5w7q4Lv/rVrwLlZs28pxKha9eugboRI0ZErmfu3LmB8vvvv+/Ff/jDH06liyKSA5pZiYgTlKxExAmx7mdV6G+mL1y40IvTHdqdii1btnjxgAEDAnXbtm3LyTbrQ3ddyK5Cj+18uPDCC71448aNgbp77rnHi3/729/mrU+10V0XRKRBULISEScoWYmIExJ56YL/HBUQ/zxV+Hj8jTfe8OIOHYLPYBwyJPjMxo4dO3rxmDFjAnXTp0+PtX2RJOrevbsXnzhxIlC3Y8eOfHen3jSzEhEnKFmJiBMScxh42WWXefGwYcMi261fvz5QvvHGG714z549gbrq6movbty4caDugw8+CJQvvfRSLz7zzDNj9FjEDd26dfPiQ4cOBepefvnlfHen3jSzEhEnKFmJiBOUrETECYk5Z3Xeeed5MRm86t5/nmrgwIGBusrKyljrnzBhQqDcuXPnyLavv/56rHWKJFGXLl0C5fHjx3uxy3cU0cxKRJygZCUiTkjMYeDSpUu9uKysLFB38OBBL66qqqrX+kePHh0oFxcX12s9Ikl30UUXBcqlpaVeHP52iEs0sxIRJyhZiYgTlKxExAmJOWflV1FRkZX1TJw40Yv9d0uszV/+8pdaYxHX3HfffYGy//epvLw8393JGs2sRMQJSlYi4gQnHhgR1+DBgwPlF1980YvDd13YtWtXoOy/tGHlypU56F126IER2eXK2E6nffv2gfKnn34aKP/jH//w4vBlDUmiB0aISIOgZCUiTlCyEhEnJPLShfry320U+OZ5Kr/w1w6SfJ5KJJ3+/funrd+9e3eeepJbmlmJiBOUrETECc4fBr7yyitefO2110a2e/bZZwPlyZMn56xPIvn0/e9/P239jBkz8tST3NLMSkScoGQlIk5QshIRJzj3dRv/gyUAYN26dV4cfjip/6GnV1xxRaBuy5YtOehd7unrNtmVpLGdid69e3tx+AEnW7duDZSvvPJKL/7qq69y2q9Toa/biEiDoGQlIk5w7tKFRYsWBcrhQz+/BQsWeLGrh30itRkwYIAXt2rVKlD3pz/9KVBO8qFfJjSzEhEnKFmJiBOUrETECU6cs7rxxhu9uEePHpHtVqxYESg/+OCDueqSSEFdeumlXhy+/Oill17Kd3fyQjMrEXGCkpWIOEHJSkSckMhzVuFrpyZNmuTFxcXFkcutXbs2UK6urs5ux0QK5Nxzzw2U+/Xr58WbNm0K1L388st56VO+aWYlIk5QshIRJyTyMHDChAmBcs+ePSPb+u8UqksVpKEaN25coNy6dWsvXr58eZ57UxiaWYmIE5SsRMQJSlYi4oREnrO69957Y7cdP368F+tSBWmo2rVrF1m3b9++PPakcDSzEhEnKFmJiBMSeRiYCf9dEo8ePVrv9Rw4cCByPf6r5lu0aBG5jjPOOCNQjns4e/z48UD5/vvv9+LDhw/HWoc0bIMHD46sW7p0aR57UjiaWYmIE5SsRMQJSlYi4gTnz1l9/PHHWVnPiy++6MWVlZWBunPOOceLR40alZXtpbNz504vnjZtWs63J8nUt29fLw7fdeHbSDMrEXGCkpWIOCGRh4HLli0LlG+66aacb3PkyJH1Wu7YsWNefOLEich2S5YsCZTLy8sj27777rv16os0LMOGDfPioqKiQN1HH33kxatWrcpbnwpJMysRcYKSlYg4QclKRJyQyHNWw4cPD5Tvu+8+L073wIiwSy65xIszueTgmWeeCZS3bt0a2XbRokVevHHjxtjbEAkrKSkJlK+//vrItv4HmYa/rtVQaWYlIk5QshIRJ9AYU3cjsu5GkhfGGBa6Dw1JksZ2+BTHypUrvXjXrl2BultuucWLG8qdOeoa25pZiYgTlKxExAlKViLiBJ2zcozOWWWXxnZy6JyViDQISlYi4gQlKxFxgpKViDhByUpEnKBkJSJOULISEScoWYmIE5SsRMQJSlYi4gQlKxFxgpKViDhByUpEnBDrrgsiIoWmmZWIOEHJSkScoGQlIk5QshIRJxQ0WZH8PcmpNu5HclOetmtIlsVsO4XkAhtfQLKaZFGM5WK3lYZHYzv76kxWJLeSPGI794XdCadnuyPGmHeNMZ1i9GccydXZ3n4cxphtxpjTjTF1Pq873JbkCpK3ZbI9kt1IriF52P7brb59l2/S2D4p32O7Bsmf2ARb5/JxZ1ZDjDGnA+gB4DIAk2vZaKPMuinpkGwM4FUACwC0BDAfwKv2fckeje0CIdkSwCQA6+O0z+gw0BjzGYDlALrYjRmSd5H8BMAn9r3BJNeS3E/yPZJdfZ3rTvKvJA+SXAigqa/uapI7fOW2JBeT3E1yL8nZJC8GMA9AH/vXcL9t24TkYyS32b+Q80g2861rIslKkp+TvDXdz0jyeyRX2j6+BeAsX117+zM38rVdZdu+TXKOb1rttSU5DUA/ALNtv2fH+LivBtAIwOPGmH8ZY54EQADXxFhWMqSxndexXWM6gCcB7InV2hiT9gVgK4ABNm6LVBZ82JYNgLcAtALQDEB3ALsA9AJQBGCsXb4JgMYAKgD8EkAxgBEAjgKYatd1NYAdNi4CsA7ALAClSO34vrZuHIDVoT7OArDE9qM5gKUAptu6QQC+QGoQlgJ4zva7LOLnfR/ATNvnqwAcBLDA1rW3yzbytX3M/mx9AXyZpu0KALeFtvUagF9H9OOXAJbX0n5CXftMr3gvje3CjG1bfzmAcqQmTN9YvtZlYu7QagD77Q55CkAz3w69xtd2bs3O9r23CUB/++F8DnvVvK17L2KH9gGwu+bDCK0vsEORmm0cAtDR914fAP+08TMAHvHVXRi1QwFcAOAYgFLfe8/VtpN8bUt8bRdkskPr+Nz/E8ALoff+B8CUQv+SN5SXxnbBxnYRUomqdybLxz0WH2qMeTuibrsvbgdgLMlf+N5rDOB8+8N9ZmzvrIqIdbYFUGGMORajb2cDKAGwhvSekUikPhDYba+Jsc2atvuMMYdC7dtGtK0yxhz2vbc9om19VAP4Tui97yD111CyR2O79ra5HNs/B/CxMeaDTBbKxqUL/h20HcA0Y8wZvleJMeZ5AJUA2tD3qSOVwWuzHcAFESc2w19m3APgCIBLfNtsYVInTWG36/+Qo7ZZ07YlydIY7SsBtCJZ4nsv3c7M9EuY6wF0DX1eXRHzZKRkhcb2Sdkc2/8GYBjJnSR3ArgCwH/Vdb4r29dZ/Q7AHSR7MaWU5A0kmyN1DHwMwN0ki0kOR+q4tTYfIvWBPWLX0ZTklbbuCwDfpf1fMWPMCbvdWSRbAwDJNiQH2vZ/BDCOZGf74T8Y1XljTAVS09OHSDYm2RfAkDraTrFt+0S19fW7Q5r6sBUAjiP1eTUhOd6+/+cM1iHZo7EdLdOxPQ7AxQC62Vc5gIcAPJBuoawmK2NMOYCfApgNYB+AzbZjMMZ8DWC4LVcBGAVgccR6jiP14ZQB2AZgh20PpH5Z1wPYSbLmfxHut9v6gOSXAN4G0MmuazmAx+1ym1H3L/stSJ1ErUJq5z+bpu0YpM4h7AUwFcBCAP+KaPsEgBEk95F8EgBILic5qbbG9vMaCuAnSJ1TuRWpQ5av6+i/5IDGdlbH9n5jzM6aF4CvAXxpjDmQrvO6RUwW2f+y3miMifwLJ+KiJIxtfTfwFJDsSbIjydNIDgJwE4BXCt0vkVOVxLGtK3NPzblITffPRGo6f6cx5qPCdkkkKxI3tnUYKCJO0GGgiDgh1mEgSU2/EsIYw7pbSVwa28lR19jWzEpEnKBkJSJOULISEScoWYmIE5SsRMQJSlYi4gQlKxFxgpKViDhByUpEnKBkJSJOULISEScoWYmIE5SsRMQJDerme6WlpYHyo48+6sU/+9nPAnVr1qwJlEeOHOnFFRXpnmgkIoWgmZWIOEHJSkScoGQlIk6IdQ92V+6mWFZWFihv2LAhsu1ppwXz9N133+3Fc+bMyW7Hskh3Cs2uJI3tHj16BMqLF5989GD79u1zvv1rr702UPb//mzfvj3n29edQkWkQVCyEhEnOH/pwtlnn+3F8+fPL2BPRE7NwIEDA+UmTZrkdftDhgwJlG+99VYvHj16dF77UhvNrETECUpWIuIEJSsRcYJz56z8lxgAwNChQ7348ssvr/d6r7rqKi8OX9awbt06L161alW9tyES1qjRyV/B66+/voA9+eZX0O69914vDn+V7dChQ3npk59mViLiBCUrEXGCc4eBs2bNCpRPnDiRlfUOHz681hgI3oVh1KhRgbrw1FkkEz/84Q+9uE+fPoG6GTNm5LUvLVu2DJQ7d+7sxSUlJYE6HQaKiERQshIRJyhZiYgTnLjrwrJly7z4uuuuC9TV95zV3r17A+Xq6movbteuXez1FBUV1Wv79aW7LmRXvsd2ly5dAuUVK1Z4cXhM/uAHP/Bi//jMFX9fAKBv375efN555wXqdu/enfXt664LItIgKFmJiBMSeelC//79A+VOnTp5cfiwL+5h4Lx58wLlN998M1A+cOCAF19zzTWBugceeCByvXfeeacXz507N1Zf5Ntr8uTJgbL/yvBBgwYF6vJx6NeqVSsvDv/eZeuyoGzRzEpEnKBkJSJOULISESck5pyV/4b4L7zwQqDurLPOirWO8MNJFy1a5MUPPfRQoO7w4cOx13P77bd7sf/OpEDwKxFNmzYN1M2ePduLjx49Grk9adhGjBjhxeE7K2zevNmLy8vL89anGv7zseFzVP5LGfbv35+vLkXSzEpEnKBkJSJOSMxhoP8mZHEP+wBg5cqVXhy+qf2ePXvq1ZfwYeD06dO9eObMmYE6/7fRw9+SX7JkiRdv2bKlXn0R940cOdKLw3cveOqpp/Lal/DzB8eMGePFx48fD9RNnTrVi5NwGkMzKxFxgpKViDhByUpEnJCYc1Zxhf971/8gxvqeo6qL/9yT/xgfAHr27JmTbYq7WrRoESj37t07sm2+v6LlvwwHCJ4f3rBhQ6DunXfeyUuf4tLMSkScoGQlIk5I5GFg+Ll9fr169cpjT1LIk/cEC/ctXV+nTJnixT/+8Y+z3i9JpiZNmgTKbdq08eLnn38+390J6NixY2Td3/72tzz2JHOaWYmIE5SsRMQJSlYi4oTEnLO64447vDhpdygcMmSIF3fv3j1Q5+9ruN/+c1by7XHw4MFAee3atV7ctWvXQJ3/Tp1VVVU56U/r1q292H8HiLDVq1fnZPvZopmViDhByUpEnKBkJSJOSMw5K/95oULw3wG0c+fOgbpJkybFWkf4wY9JuK2G5N+RI0cCZf/tgX70ox8F6l5//XUvDt9+KK7wg1M7dOgQKPtvC5PuocZJO1ccppmViDhByUpEnMB000KvEVl3o1O0adMmLw5PY/2Ki4tzsv3HH3/ci++6667Yy23bts2Lx44dG6jLxX8FG2NYdyuJKx9j+6KLLvLi3/zmN4G6G264wYvDX9OJK3y3kfDvtP/OCv6vjoU1b948UA4fzuZaXWNbMysRcYKSlYg4QclKRJyQmEsX8m3ZsmWBcqdOneq1nr///e9enPSvK0hhbNy40YtvvvnmQF23bt28uKysrF7rf+mll9LWz58/34vDd7r1y/c5qkxpZiUiTlCyEhEnJOYwMN3dOP2uu+66yLqnn346UD7//PMj24a3Ud+rdwt95b24zX9HBn+cTZ9++mmsduEr4ZN251DNrETECUpWIuIEJSsRcUJizln5H/Y4Y8aMyHavvfZaoJzuXFMm56Hitp03b17sdYokgf98cLqv2yTtHFWYZlYi4gQlKxFxQmIOAxcvXuzFEydODNT5b4yXK/4b523YsCFQd/vtt3txZWVlzvsikk3+uzDEuctKUmlmJSJOULISEScoWYmIExJzzqqiosKLR48eHagbOnSoF99zzz052f60adO8eM6cOTnZhkghNG3aNLIu6Xda8NPMSkScoGQlIk5IzAMj4ho0aFCg7L+sIHwHhCVLlnhx+I4M4St5/TfR8z8EImn0wIjsStLYzpWdO3d6caNGwTM/Dz/8sBc/8cQTeetTbfTACBFpEJSsRMQJSlYi4gTnzll92+mcVXZ9G8b20qVLvXjmzJmBunfeeSff3Ymkc1Yi0iAoWYmIE3QY6BgdBmaXxnZy6DBQRBoEJSsRcYKSlYg4QclKRJygZCUiTlCyEhEnKFmJiBOUrETECUpWIuIEJSsRcUKsr9uIiBSaZlYi4gQlKxFxgpKViDhByUpEnKBkJSJOULISESf8P5xanyeowZZxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFOFv2R-E6d3",
        "outputId": "4d97cf47-072e-4ec7-c70d-41e71b059cf7"
      },
      "source": [
        "# - - - - - - - SAVE THE MODEL - - - - - - - -\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-ngHbOkFIVY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}